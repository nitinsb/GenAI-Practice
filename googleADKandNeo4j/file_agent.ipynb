{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c909b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools import ToolContext\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "# For type hints\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7373b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-CSv3lPIbrHrIVQUjIiWZXoe7m5YcX', created=1761008557, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_f64f290af2', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready! How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=27, total_tokens=40, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "OpenAI is ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6dd6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_suggestion_agent_instruction = \"\"\"\n",
    "You are a constructive critic AI reviewing a list of files. Your goal is to suggest relevant files\n",
    "for constructing a knowledge graph.\n",
    "\n",
    "**Task:**\n",
    "Review the file list for relevance to the kind of graph and description specified in the approved user goal. \n",
    "\n",
    "For any file that you're not sure about, use the 'sample_file' tool to get \n",
    "a better understanding of the file contents. \n",
    "\n",
    "Only consider structured data files like CSV or JSON.\n",
    "\n",
    "Prepare for the task:\n",
    "- use the 'get_approved_user_goal' tool to get the approved user goal\n",
    "\n",
    "Think carefully, repeating these steps until finished:\n",
    "1. list available files using the 'list_available_files' tool\n",
    "2. evaluate the relevance of each file, then record the list of suggested files using the 'set_suggested_files' tool\n",
    "3. use the 'get_suggested_files' tool to get the list of suggested files\n",
    "4. ask the user to approve the set of suggested files\n",
    "5. If the user has feedback, go back to step 1 with that feedback in mind\n",
    "6. If approved, use the 'approve_suggested_files' tool to record the approval\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb92996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tools defined in previous lesson\n",
    "from tools import get_approved_user_goal\n",
    "from helper import get_neo4j_import_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b2d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tool: List Import Files\n",
    "\n",
    "# this constant will be used as the key for storing the file list in the tool context state\n",
    "ALL_AVAILABLE_FILES = \"all_available_files\"\n",
    "\n",
    "def list_available_files(tool_context:ToolContext) -> dict:\n",
    "    f\"\"\"Lists files available for knowledge graph construction.\n",
    "    All files are relative to the import directory.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a {ALL_AVAILABLE_FILES} key with list of file names.\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    # get the import dir using the helper function\n",
    "    import_dir = Path(get_neo4j_import_dir())\n",
    "\n",
    "    # get a list of relative file names, so files must be rooted at the import dir\n",
    "    file_names = [str(x.relative_to(import_dir)) \n",
    "                 for x in import_dir.rglob(\"*\") \n",
    "                 if x.is_file()]\n",
    "\n",
    "    # save the list to state so we can inspect it later\n",
    "    tool_context.state[ALL_AVAILABLE_FILES] = file_names\n",
    "\n",
    "    return tool_success(ALL_AVAILABLE_FILES, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1167dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Sample File\n",
    "# This is a simple file reading tool that only works on files from the import directory\n",
    "def sample_file(file_path: str, tool_context: ToolContext) -> dict:\n",
    "    \"\"\"Samples a file by reading its content as text.\n",
    "    \n",
    "    Treats any file as text and reads up to a maximum of 100 lines.\n",
    "    \n",
    "    Args:\n",
    "      file_path: file to sample, relative to the import directory\n",
    "      \n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content,\n",
    "            along with a sampling of the file.\n",
    "            Includes a 'status' key ('success' or 'error').\n",
    "            If 'success', includes a 'content' key with textual file content.\n",
    "            If 'error', includes an 'error_message' key.\n",
    "            The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    # Trust, but verify. The agent may invent absolute file paths. \n",
    "    if Path(file_path).is_absolute():\n",
    "        return tool_error(\"File path must be relative to the import directory. Make sure the file is from the list of available files.\")\n",
    "    \n",
    "    import_dir = Path(get_neo4j_import_dir())\n",
    "\n",
    "    # create the full path by extending from the import_dir\n",
    "    full_path_to_file = import_dir / file_path\n",
    "    \n",
    "    # of course, _that_ may not exist\n",
    "    if not full_path_to_file.exists():\n",
    "        return tool_error(f\"File does not exist in import directory. Make sure {file_path} is from the list of available files.\")\n",
    "    \n",
    "    try:\n",
    "        # Treat all files as text\n",
    "        with open(full_path_to_file, 'r', encoding='utf-8') as file:\n",
    "            # Read up to 100 lines\n",
    "            lines = list(islice(file, 100))\n",
    "            content = ''.join(lines)\n",
    "            return tool_success(\"content\", content)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return tool_error(f\"Error reading or processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458b7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Set/Get suggested files\n",
    "SUGGESTED_FILES = \"suggested_files\"\n",
    "\n",
    "def set_suggested_files(suggest_files:List[str], tool_context:ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"Set the suggested files to be used for data import.\n",
    "\n",
    "    Args:\n",
    "        suggest_files (List[str]): List of file paths to suggest\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a {SUGGESTED_FILES} key with list of file names.\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    tool_context.state[SUGGESTED_FILES] = suggest_files\n",
    "    return tool_success(SUGGESTED_FILES, suggest_files)\n",
    "\n",
    "# Helps encourage the LLM to first set the suggested files.\n",
    "# This is an important strategy for maintaining consistency through defined values.\n",
    "def get_suggested_files(tool_context:ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"Get the files to be used for data import.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a {SUGGESTED_FILES} key with list of file names.\n",
    "                If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    return tool_success(SUGGESTED_FILES, tool_context.state[SUGGESTED_FILES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95dd70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Approve Suggested Files\n",
    "# Just like the previous lesson, you'll define a tool which\n",
    "# accepts no arguments and can sanity check before approving.\n",
    "APPROVED_FILES = \"approved_files\"\n",
    "\n",
    "def approve_suggested_files(tool_context:ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"Approves the {SUGGESTED_FILES} in state for further processing as {APPROVED_FILES}.\n",
    "    \n",
    "    If {SUGGESTED_FILES} is not in state, return an error.\n",
    "    \"\"\"\n",
    "    if SUGGESTED_FILES not in tool_context.state:\n",
    "        return tool_error(\"Current files have not been set. Take no action other than to inform user.\")\n",
    "\n",
    "    tool_context.state[APPROVED_FILES] = tool_context.state[SUGGESTED_FILES]\n",
    "    return tool_success(APPROVED_FILES, tool_context.state[APPROVED_FILES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47905ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tools for the file suggestion agent\n",
    "file_suggestion_agent_tools = [get_approved_user_goal, list_available_files, sample_file, \n",
    "    set_suggested_files, get_suggested_files,\n",
    "    approve_suggested_files\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e465ed5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'file_suggestion_agent_v1' created.\n"
     ]
    }
   ],
   "source": [
    "# Finally, construct the agent\n",
    "\n",
    "file_suggestion_agent = Agent(\n",
    "    name=\"file_suggestion_agent_v1\",\n",
    "    model=llm, # defined earlier in a variable\n",
    "    description=\"Helps the user select files to import.\",\n",
    "    instruction=file_suggestion_agent_instruction,\n",
    "    tools=file_suggestion_agent_tools,\n",
    ")\n",
    "\n",
    "print(f\"Agent '{file_suggestion_agent.name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed33617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "file_suggestion_caller = await make_agent_caller(file_suggestion_agent, {\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"A multi-level bill of materials for manufactured products, useful for root cause analysis..\"\n",
    "    }   \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eacc586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Initial Conversation\n",
    "\n",
    "# nudge the agent to look for files. in the full system, this will be the natural next step\n",
    "await file_suggestion_caller.call(\"What files can we use for import?\")\n",
    "\n",
    "session_end = await file_suggestion_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "# expect that the agent has listed available files\n",
    "print(\"Available files: \", session_end.state[ALL_AVAILABLE_FILES])\n",
    "\n",
    "# the suggested files should be reasonable looking CSV files\n",
    "print(\"Suggested files: \", session_end.state[SUGGESTED_FILES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0843038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agree with the file suggestions\n",
    "await file_suggestion_caller.call(\"Yes, let's do it\")\n",
    "\n",
    "session_end = await file_suggestion_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"Approved files: \", session_end.state[APPROVED_FILES])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (studies)",
   "language": "python",
   "name": "studies"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
